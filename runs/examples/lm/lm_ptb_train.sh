python $SEQ2SEQROOT/main.py \
    --run runs/examples/ \
    --model LSTMLanguageModel \
    --train data/lm/train \
    --dev data/lm/valid \
    --in_vocab data/lm/vocab \
    --out_vocab data/lm/vocab \
    --format lm \
    --val_metric perplexity \
    --cutoff 0 \
    --mem 11264 \
    --gpus 1 \
    --imports lm \
    --checkpoint lm.model \
    --epochs 100 \
    --trainer sgd \
    --lr 1 \
    --lr_decay 0.85 \
    --patience 3 \
    --monitor none \
    --batch_size 16 \
    --val_batch_size 64
